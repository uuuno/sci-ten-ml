{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTデータをフェッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本来はこれで取れるが、なぜか「Internal Server Eroor」になるので、次の方法で代替する\n",
    "# from sklearn.datasets import fetch_mldata\n",
    "# mnist = fetch_mldata('MNIST original')\n",
    "# mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "try:\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "except Exception as ex:        \n",
    "    from six.moves import urllib\n",
    "    from scipy.io import loadmat\n",
    "    import os\n",
    "\n",
    "    mnist_path = os.path.join(\".\", \"datasets\", \"mnist-original.mat\")\n",
    "\n",
    "    # download dataset from github.\n",
    "    mnist_alternative_url = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n",
    "    response = urllib.request.urlopen(mnist_alternative_url)\n",
    "    with open(mnist_path, \"wb\") as f:\n",
    "        content = response.read()\n",
    "        f.write(content)\n",
    "\n",
    "    mnist_raw = loadmat(mnist_path)\n",
    "    mnist = {\n",
    "        \"data\": mnist_raw[\"data\"].T,\n",
    "        \"target\": mnist_raw[\"label\"][0],\n",
    "        \"COL_NAMES\": [\"label\", \"data\"],\n",
    "        \"DESCR\": \"mldata.org dataset: mnist-original\",\n",
    "    }\n",
    "    print(\"Done!\")\n",
    "    \n",
    "# Source : https://stackoverflow.com/questions/43149272/cannot-get-mnist-database-through-anaconda-jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([ 0.,  0.,  0., ...,  9.,  9.,  9.])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape #教師データ、70000のデータで、１つのデータの特徴量は784(28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  94,\n",
       "       109, 191, 255, 222,  41,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       218, 247, 252, 252, 253, 200,  21,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11,\n",
       "        58, 181, 253, 252, 252, 252, 253, 241,  61,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0, 155, 252, 252, 253, 252, 252, 252, 253, 179,   1,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0, 110, 232, 252, 252, 253, 252, 252, 252, 253, 252,  71,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  11, 155, 253, 252, 252, 252, 253, 252, 252, 252, 253,\n",
       "       189,  10,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  58, 252, 253, 252, 252, 252, 217, 215, 221,\n",
       "       252, 253, 231,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 125, 221, 252, 253, 252, 231, 108,   0,\n",
       "         0, 120, 252, 253, 128,  31,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0, 110, 253, 253, 253, 255, 253, 217,\n",
       "         0,   0,   0, 120, 253, 255,  98,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  42, 149, 252, 252, 252, 253,\n",
       "       148,  30,   0,   0,  21, 181, 252, 222, 128,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 144, 252, 252, 252,\n",
       "       252, 154,  10,   0,   0,  63, 196, 252, 252, 144,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21, 206, 252,\n",
       "       252, 252, 252,   0,   0,   0,   0,   0, 217, 252, 252, 144,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 182,\n",
       "       253, 253, 253, 175,  62,   0,   0,   0,   0, 171, 253, 253, 253,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  98, 252, 252, 252, 113,   0,   0,   0,  11, 155, 253, 252,\n",
       "       252, 128,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  53, 232, 252, 252, 252, 241, 181, 182, 181, 191, 252,\n",
       "       253, 252, 122,  31,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  31, 211, 252, 252, 252, 252, 252, 253, 252,\n",
       "       252, 252, 253, 252, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,  32, 212, 253, 253, 253, 253, 253,\n",
       "       255, 253, 253, 253, 255, 159,  41,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  10, 149, 252, 252, 252,\n",
       "       252, 252, 253, 252, 252, 252, 191,  15,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  32, 236,\n",
       "       252, 252, 252, 252, 253, 252, 205, 154, 154,  10,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  62, 252, 252, 252, 252, 253, 128,  31,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[123] # 適当に１つのデータを見て見る\n",
    "# 0（白）~255(黒)のピクセルの明度が入っていることがわかる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape #正解ラベル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([    0,     1,     2, ..., 60977, 60978, 60979]),)\n",
      "(array([30596, 30597, 30598, ..., 66028, 66029, 66030]),)\n",
      "(array([54051, 54052, 54053, ..., 69997, 69998, 69999]),)\n",
      "[ 9.  9.  9.  9.  9.  9.  9.  9.  9.  9.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.where(y == 0)) #適当に「0」の位置を確認\n",
    "print(np.where(y == 5))\n",
    "print(np.where(y == 9))\n",
    "# 0~9までのデータが順番に格納されていることがわかる\n",
    "\n",
    "print(y[59990:60000])\n",
    "print(y[60000:60010])\n",
    "# さらに0~60000番目までは教師データ、60001~70000番目まではテストデータという具合に分けられていることがわかる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データから数字を描画してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "5.0\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1067a8828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[36000] # 36000番目のデータ見てみる\n",
    "print(some_digit.shape)\n",
    "print(y[36000])\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "print(some_digit_image.shape)\n",
    "plt.imshow(some_digit_image)\n",
    "# plt.imshow(some_digit_image, cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練セットとテストセットに分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000 60000 10000\n"
     ]
    }
   ],
   "source": [
    "# それぞれを変数に格納\n",
    "X_train = X[:60000]\n",
    "X_test = X[60000:]\n",
    "y_train = y[:60000]\n",
    "y_test = y[60000:]\n",
    "print(len(X_tarin), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練セットをシャッフルしておく\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train = X_train[shuffle_index]\n",
    "y_train = y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二項分類器の訓練 (5かどうかを見分ける判別器)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5) #各要素にアクセスし、５ならばTrue, それ以外はFalseにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uno/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 確率的勾配降下法で試してみる\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True], dtype=bool)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([some_digit]) #さきほど描画した９番を予測してみる --> 確かにFalseになる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性能評価\n",
    "分類タスクの評価は回帰に比べ、難しい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9647,  0.9645,  0.9512])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交差検証の実装(cross_val_scoreでやる場合)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9647\n",
      "0.9645\n",
      "0.9512\n"
     ]
    }
   ],
   "source": [
    "# 層化抽出を行なって、各クラスの比率にあったフォールドを作成する場合\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = (y_train_5[train_index])\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = (y_train_5[test_index])\n",
    "\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred))\n",
    "\n",
    "# 精度が90%を超えているが、これは5が全体の10％の割合でしか含まれないからであり、決して高い数字ではない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
